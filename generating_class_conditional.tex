%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% From a template maintained at https://github.com/jamesrobertlloyd/cbl-tikz-poster
%
% Code near the top should be fairly standard and not need to be changed
%  - except for the document class
% Code lower down is more likely to be customised
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pdfminorversion=4
\documentclass[landscape,a0b,final,a4resizeable]{include/a0poster}


\usepackage{multicol}
\usepackage{color}
\usepackage{morefloats}
\usepackage[pdftex]{graphicx}
\usepackage{rotating}
\usepackage{amsmath, amsthm, amssymb, bm}
\usepackage{array}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}


\usepackage{include/picins}
\usepackage{tikz}
\usepackage{algorithm}% http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
% \usepackage{algorithmic}
% \algsetup{linenosize=\small}
\usepackage{setspace}
\usepackage[hypcap=false,font=small,labelfont=bf]{caption} 
\usepackage{makecell}
\usetikzlibrary{shapes.geometric,arrows,chains,matrix,positioning,scopes,calc}
\tikzstyle{mybox} = [draw=white, rectangle]
\definecolor{darkblue}{rgb}{0,0.08,0.45}
\definecolor{blue}{rgb}{0,0,1}



\usepackage{nicefrac}
\newcommand{\vect}[1]{\underline{\smash{#1}}}
\renewcommand{\v}[1]{\vect{#1}}
\newcommand{\reals}{\mathds{R}}
\newcommand{\sX}{\mathcal{X}}
\newcommand{\sD}{\mathcal{D}}
\newcommand{\br}{}%{^{\text{\textnormal{ r}}}}
\newcommand{\cat}{^{\text{\textnormal{c}}}}

\usepackage{dsfont}

\input{include/preamble.sty}
%\input{include/preamble2.sty}

%\usepackage{tabularx}

\input{include/jlposter.tex}


\newcommand\transpose{{\textrm{\tiny{\sf{T}}}}}
\newcommand{\note}[1]{}
\newcommand{\hlinespace}{~\vspace*{-0.15cm}~\\\hline\\\vspace*{0.15cm}}
\newcommand{\embeddingletter}{g}
\newcommand{\bo}{{\sc bo}}
%\newcommand{\gp}{{\sc gp}}
\newcommand{\agp}{Arc \gp}



\begin{document}
\begin{poster}

% Potentially add some space at the top of the poster
\vspace{0\baselineskip}



%%% Header
\begin{center}
\begin{pcolumn}{0.99}

\newcommand{\logowidth}{0.06\textwidth}  % width mauna decomp

\pbox{0.99\textwidth}{}{linewidth=2mm,framearc=0.3,linecolor=camdarkblue,fillstyle=gradient,gradangle=0,gradbegin=white,gradend=white,gradmidpoint=1.0,framesep=1em}{
%%% U Toronto Logo
\hspace{2.3cm}
\begin{minipage}[c][][b]{\logowidth}
%  \begin{center}
    \vspace{-.18in}
    \includegraphics[width=8cm,trim=9em 0em 9em 0em, clip]{badges/toronto}
   	% \hspace{35cm}
      \includegraphics{badges/uot_text.png}
\end{minipage}
% \hspace{0.3cm}
% %
% %
% %%% Another Logo
% \begin{minipage}[c][][b]{\logowidth}
% %  \begin{center}
%     \vspace{.978in}
%     \includegraphics[width=6cm]{badges/cambridgecrest}
%     \includegraphics[width=6cm]{badges/unicamtext.pdf}
% %another 
% %  \end{center}
% \end{minipage}
%
%
%%% Title
\hspace{-5.0cm}
\begin{minipage}[c][9cm][c]{0.94\textwidth}
  \begin{center}
    \vspace{3.5cm}
    {\sffamily \VeryHuge \textbf{Generating Class-conditional Images\\\vspace{5.0mm} with Gradient-based Inference}}\\[10mm]
    {\huge\sffamily \Huge Bowen Xu, David Acuna, David Duvenaud\\[7.5mm]
    \Large \texttt{\{xubo3, davidj, duvenaud\}@cs.toronto.edu}
    }
  \end{center}
\end{minipage}
%
%
% % Harvard
% \begin{minipage}[c][][b]{\logowidth}
%   \begin{flushright}
% %    \includegraphics[width=6cm,angle=0]{badges/cambridgecrest}
% %    \vspace{.1in}
% %    \includegraphics[width=6cm,angle=0]{unicamtext.pdf}
%     \includegraphics[width=8cm,trim=3.2em 0em 3.2em 3em, clip]{badges/harvard}
% %University of Cambridge 
%   \end{flushright}
% \end{minipage}
% %
% \hspace{1cm}
% 
% \begin{minipage}[c][][b]{\logowidth}
% %    \includegraphics[width=6cm,angle=0]{badges/cambridgecrest}
% %    \vspace{.1in}
% %    \includegraphics[width=6cm,angle=0]{unicamtext.pdf}
%     \includegraphics[width=8cm,trim=0em 0em 0em 0em, clip]{badges/uni-freiburg}
% \end{minipage}
%
% \hspace{1cm}
% % 
% \begin{minipage}[c][][b]{\logowidth}
% %    \includegraphics[width=6cm,angle=0]{badges/cambridgecrest}
% %    \vspace{.1in}
% %    \includegraphics[width=6cm,angle=0]{unicamtext.pdf}
%     \includegraphics[width=8cm,trim=0em 0em 0em 0em, clip]{badges/oxford}
% \end{minipage}

}
\end{pcolumn}
\end{center}

\vspace*{2.5cm}

\large


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Begin of Document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%% Begin of Multicols-Enviroment
\begin{multicols}{3}
% 
\mysection{Main idea}
%
% 
\vspace{0.2in}
% 
% \begin{minipage}[c]{1\columnwidth}
\begin{itemize}
	\item Gradient descent on images is a promising approach to generating class-conditional images.
	\item This method produces high-resolution class-conditional images with crisp details and coherent overall structure.
	 %  often produces unrepresentative super-stimuli.
	\item Even better, we sample from $p(\textnormal{image} | \textnormal{class})$ using gradient-based MCMC methods.
	\item Our approach produces realistic and content-diverse class-conditional images.
	% \item The number of architecture-dependent hyperparameters changes with different architectures.
	\item Our method removes the need for \emph{ad-hoc} tweaks to the objective when longer iterations are introduced.
\end{itemize}
% \end{minipage}
% \begin{minipage}[c]{0.35\columnwidth}
% \begin{centering}
% \begin{tabular}{c}
% \input{tables/architecture-comparison} \\
% %\textcolor{darkblue}{ [Rasmussen, 1999]}
% \end{tabular}
% \end{centering}
% \end{minipage}

\vspace{0.5in}

\mysection{Previous Work}
% 
% approach, due to Nguyen et.\ al.\ \cite{Nguyen2016}, 
A previous approach by Nguyen et.\ al.\ \cite{Nguyen2016} uses gradient-based optimization of images to do approximate 
% \emph{maximum a posteriori probability}
 MAP estimation, synthesizing large (227 x 227) class-conditional images.\\
% \begin{minipage}

\begin{center} 
  \centering
  \includegraphics{figures/img}
  % \caption{Architecture using the DGN and DNN.}
  \label{fig:net}
\end{center}

\begin{itemize}
\item An initial image is specified by a random vector $z \thicksim \mathcal{N}(0, I)$.
 \item This vector is passed through a pre-trained image generation network $g_\theta(z)$.
\item The generated image is fed into a pre-trained classification network.
 \item The latent vector is then optimized using backpropagation.
 % according to the gradient of the chosen class probability with respect to the image, multiplied by the gradient of the image with respect to the latent vector, using backpropagation.
\end{itemize}
\vspace{1cm}
\mysection{Our contribution}
We use gradient-based MCMC methods to approximately sample from the class-conditional posterior:\\
\begin{equation*}
    \hat z \thicksim p(z|\textnormal{class}) \propto p(\textnormal{class} | g_\theta(z)) p(z) \qquad \textnormal{where} \qquad p(z) = \mathcal{N}(0, I)
    %\qquad \textnormal{where} \qquad p(z | class) = p(g_\theta(z) | class)
    % \label{eq:sampling}
\end{equation*}
\linebreak
and $p(\textnormal{class} | g_\theta(z))$ is the classification network.\\

We adopt:
\begin{itemize}
\item Hamiltonian Monte Carlo (HMC) 
\item Metropolis-adjusted-Langevin-algorithm (MALA) 
\end{itemize}
% \subsection*{Algorithm}
% \begin{algorithm}[H]
% % \setstretch{1.02}
%     % \caption{MAP with Clipping\cite{Nguyen2016}} %\label{evalgd}
%     \label{alg:activation_maximization}
%     \begin{algorithmic}[1]
%          \State $z \thicksim N(0,I)$
%          \For{ iterations }
%          \State $g= \nabla log(p(\textnormal{class}|z)p(z))$
%          \State \textbf{$z = z+\alpha g$}
%          \State $z= clip(z)$
%           \EndFor
%       \end{algorithmic}
% \end{algorithm}
% \vspace{-0.05in}
 

\newpage 

\mysection{Experiments and Results}
 \vspace{-0.05cm}
\begin{align*}
% \input{figures/semicylinder}\label{fig:cylinder}
% \begin{figure}[h]
  % \centering
  %\includegraphics[width=\textwidth]{ComparisonImagebyImage_wo_clipping}
  \hspace{-2.0cm}
  \includegraphics[width=32cm,keepaspectratio=false]{figures/comparison_final_transpose}
  % [scale=0.5725]
  % \caption{Images generated with MAP, MALA, and HMC.}
  % \label{fig:robustness}
\end{align*}
% 
\mysection{Automatically Evaluating Image Quality}

We use a discriminator \cite{Radford2015}, trained on ImageNet, to output the probability of an image being natural versus synthesized.\\

\begin{minipage}[c]{1\columnwidth}
        \centering
        \resizebox{\textwidth}{!}{
        \begin{tabular}{ ccccc}
            %\hline
              & \makecell{MAP with\\ class-specific regularization}  & \makecell{MALA with\\ class-specific regularization} & MALA & HMC\\
            \midrule 
            Average log-probability & -6.00 & {\bf -5.53} & -9.79 & -7.96
		\end{tabular}}
        % \caption{Average log-probability of synthetic images being real.}
        \label{table:dt_test}
\end{minipage}



\newpage
\mysection{Diversity of Image Contents}
\vspace{-0.5cm}
\begin{align*}
% \input{figures/semicylinder}\label{fig:cylinder}
% \begin{figure}[h]
% 
  %\includegraphics[width=\textwidth]{ComparisonImagebyImage_wo_clipping}
   % \hspace{-1.0cm}
   % \hspace{0.8cm}
  \includegraphics[width=33cm,keepaspectratio=false]{figures/moreRepresentative}
  % [scale=0.5725]
  % \caption{Images generated with MAP, MALA, and HMC.}
  % \label{fig:robustness}
\end{align*}



\mysection{Advantages and Limitations}
\begin{itemize}
	\setlength\itemsep{0.4em}
	\item[$+$] Produces high-resolution images with crisp details and coherent overall structure.
	\item[$+$] Generates more content-diverse images.
	\item[$+$] Removes the need for class-specific regularization when longer iterations are introduced.
	% \item[$+$] If longer iterations are introduced clipping constraints are not required.
	% \item[$-$] Slow convergence for high-dimensional data spaces.
	\item[$-$] Small step sizes and longer iterations are required.
\end{itemize}
% \begin{minipage}[c]{0.95\columnwidth}
% %\begin{table}[h!]
% %\caption{{\small \label{tab:nn_error}}}
% %\label{tbl:nn_nmse}
% \input{tables/mcmc-table.tex}
 



\vspace{1.cm}
\mysection{Future Work}
	\begin{itemize}
		\setlength\itemsep{0.4em}
		\item Use the Hamiltonian Variational Inference (HVI) model \cite{2014arXiv1410.6460S}.
		\item Generate images from text.
		\item Generate other media such as sound and video.
 	\end{itemize}
% %\begin{figure}[t!]
% 	\centering
% %	\begin{subfigure}[]{0.3\textwidth}
% \begin{tabular}{cc}
% \includegraphics[width=0.45\columnwidth]{figures/mnist.pdf} &
% \includegraphics[width=0.45\columnwidth]{figures/cifar10.pdf} \\
% MNIST &  CIFAR-10
% \end{tabular}		


% \begin{tabular}{c}
% 		\includegraphics[width=0.45\columnwidth]{figures/fevals_per_layer.pdf} \\
% Architectures searched
% \end{tabular}
		
%		\label{fig:proparchs}
%	\end{subfigure}
%	\caption{Bayesian optimization results using the arc kernel.}
%	\label{fig:arcbo}
%\vspace{-0.3cm}
%\end{figure}

\vspace{1.cm}
% \hspace{-1.0cm}

\mysection{Bibliography}
\small
\begingroup
\renewcommand{\section}[2]{}%
\bibliography{bib}
\endgroup
\bibliographystyle{ieeetr}

\vspace{1.5cm}
 \begin{center}
\begin{minipage}[c]{0.2\columnwidth}
  \includegraphics[width=8cm]{photos/xu}
  \captionsetup{labelformat=empty}
  \captionof{figure}{Bowen Xu}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[c]{0.2\columnwidth}
  \includegraphics[width=8cm]{photos/acuna}
  \captionsetup{labelformat=empty}
  \captionof{figure}{David Acuna}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[c]{0.2\columnwidth}
  \includegraphics[width=8cm]{photos/duvenaud.png}
  \captionsetup{labelformat=empty}
  \captionof{figure}{David Duvenaud}
\end{minipage}
\end{center}
 
%\paragraph{Code}
%Code available at \texttt{http://???}
%
%Paper available at \texttt{http://???}
 

\end{multicols}
\end{poster}
\end{document}

